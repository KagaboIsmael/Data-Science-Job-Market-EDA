{"cells":[{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"markdown","metadata":{},"source":["  "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import pandas as pd\n","import re\n","import string\n","from wordcloud import WordCloud\n","import matplotlib.pyplot as plt\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import WordNetLemmatizer\n","import numpy as np"]},{"cell_type":"markdown","metadata":{},"source":["## Data Preparation<a id='DataPreparation'></a>"]},{"cell_type":"markdown","metadata":{},"source":["This data set contains 6953 rows with 5 columns: Position, Company, Job Description, Review, and Location."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Load and view data\n","df = pd.read_csv('../input/data-scientist-job-market-in-the-us/alldata.csv')\n","df.head()"]},{"cell_type":"markdown","metadata":{},"source":["### Data Cleaning <a id='cleaning'></a>"]},{"cell_type":"markdown","metadata":{},"source":["In order to clean the data, I checked for the number of NaNs in each column. Since the Review column has the greatest number of NaNs, I decided to drop it all together since I won't be doing analysis on it. For the rest of the NaNs, I filtered the data frame to leave out all the rows containing null values. "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Check if there are any NaNs in the data\n","df.isnull().sum()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Drop column Review from the data\n","df.drop(columns = 'reviews', inplace = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Filtered the data set to remove the rest of the rows containing NaNs value\n","df.drop(index = df[df['position'].isnull()].index, inplace = True)\n","df.isnull().any()"]},{"cell_type":"markdown","metadata":{},"source":["### Populate New Columns <a id='newclumn'></a>"]},{"cell_type":"markdown","metadata":{},"source":["In order to aggregate the data, I've created City and State columns based on the Location column of the original data set. "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Create city and state columns to better aggregate the data\n","df['location'] = df.location.apply(lambda x: re.sub('\\d*','',str(x)))\n","df['city'] = df.location.apply(lambda x: x.split(',')[0].strip())\n","df['state'] = df.location.apply(lambda x: x.split(',')[1].strip())\n","df['location'] = df['city']+ ', ' + df['state']\n","df.head()"]},{"cell_type":"markdown","metadata":{},"source":["## Exporatory Data Analysis<a id='eda'></a>"]},{"cell_type":"markdown","metadata":{},"source":["In this section, I'll utilize **pandas** and **matplotlib** to answer the following questions:\n","\n","- What is the is the most common job to appear when searching for 'Data Science'?\n","- Which company hire the most Data Science job?\n","- From the data, which cities and state hire the most?"]},{"cell_type":"markdown","metadata":{},"source":["### Positions by Job Title <a id='title'></a>"]},{"cell_type":"markdown","metadata":{},"source":["Since position titles are varied from one company to another, the following code block will categorize the titles into 5 groups: Data Scientist, Machine Learning Engineer, Data Analyst, Data Science Manager, and Others.\n","\n","*Note: I want to give credit to Pramod Manjegowda for the following code block. Pramad followed a machine learning approach toward this data set. You can take a look at his notebook <a href ='https://www.kaggle.com/pramod7/data-science-jobs-opening-in-us-analysis-ml'>here</a>.* "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Group position name into 5 types\n","data = df.copy()\n","data['position']=[x.upper() for x in data['position']]\n","data.loc[data.position.str.contains(\"SCIENTIST\"), 'position'] = 'Data Scientist'\n","\n","data.loc[data.position.str.contains('ENGINEER'),'position']='Machine Learning Engineer'\n","data.loc[data.position.str.contains('PRINCIPAL STATISTICAL PROGRAMMER'),'position']='Machine Learning Engineer'\n","data.loc[data.position.str.contains('PROGRAMMER'),'position']='Machine Learning Engineer'\n","data.loc[data.position.str.contains('DEVELOPER'),'position']='Machine Learning Engineer'\n","\n","data.loc[data.position.str.contains('ANALYST'), 'position'] = 'Data Analyst'\n","data.loc[data.position.str.contains('STATISTICIAN'), 'position'] = 'Data Analyst'\n","\n","data.loc[data.position.str.contains('MANAGER'),'position']='Data Science Manager'\n","data.loc[data.position.str.contains('CONSULTANT'),'position']='Data Science Manager'\n","data.loc[data.position.str.contains('DATA SCIENCE'),'position']='Data Science Manager'\n","data.loc[data.position.str.contains('DIRECTOR'),'position']='Data Science Manager'\n","\n","data.position=data[(data.position == 'Data Scientist') | (data.position == 'Data Analyst') | (data.position == 'Machine Learning Engineer') | (data.position == 'Data Science Manager')]\n","data.position=['Others' if x is np.nan else x for x in data.position]"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"trusted":true},"outputs":[],"source":["title = data.groupby(['position']).count().sort_values('company')\n","\n","title['company'].plot(kind='barh',figsize = (10,5))\n","plt.xlabel('Count', size = 12)\n","plt.ylabel('')\n","plt.yticks(size = 10)\n","plt.xticks(size = 10)\n","plt.title('Number of Positions by Job Title', size = 20)\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{},"source":["### Positions by Companies <a id='company'></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"trusted":true},"outputs":[],"source":["company = df.groupby(['company']).count().sort_values('position').tail(20)\n","\n","company['position'].plot(kind='barh',figsize = (10,5))\n","plt.xlabel('Count', size = 12)\n","plt.ylabel('')\n","plt.yticks(size = 10)\n","plt.xticks(size = 10)\n","plt.title('Number of Positions by Companies (Top 20)', size = 20)\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["From the chart, we can see that Amazon.com hire the most candidate, follow by Ball Aerospace, Microsoft and Google. "]},{"cell_type":"markdown","metadata":{},"source":["### Positions by Cities <a id='city'></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"trusted":true},"outputs":[],"source":["city = df.groupby(['location']).count().sort_values('position').tail(20)\n","\n","city['position'].plot(kind='barh',figsize = (10,5))\n","plt.xlabel('Count', size = 12)\n","plt.ylabel('')\n","plt.yticks(size = 10)\n","plt.xticks(size = 10)\n","plt.title('Number of Positions by Cities (Top 20)', size = 20)\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["It appears that the top 5 cities that hire the most data science related job are New York, Seattle, Cambridge, Boston, and San Francisco. It makes sense since those cities are the technology hub of the country. "]},{"cell_type":"markdown","metadata":{},"source":["### Positions by States <a id='state'></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["state = df.groupby('state').count().sort_values('position',ascending = False)\n","\n","state['position'].plot(kind = 'bar',figsize = (10,5) ,width = 0.85)\n","plt.xlabel('')\n","plt.ylabel('Count',size = 12)\n","plt.title('Number of Positions by State', size = 20)\n","plt.yticks(size = 10)\n","plt.xticks(size = 10, rotation = 720)\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["Even though the city with the highest number of positions is New York, the highest number of position by state is California, follows by Massachusetts and Washington. "]},{"cell_type":"markdown","metadata":{},"source":["### Position by State and Job Title <a id='statetitle'></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["data = data[data['position'] != 'Others']\n","i = 1\n","color = ['#A92420','#8A6FDF','#135390','#FDA649']\n","fig = plt.figure(figsize=(20,10))\n","for position in data.position.unique():\n","    x = data[data['position']== str(position)].groupby(['state']).count().sort_values('company')\n","    plt.subplot(2, 2, i)\n","    i += 1\n","    plt.bar(x.index,x['company'], color = color[i-2])\n","    plt.xlabel('')\n","    plt.xticks(size = 10)\n","    plt.title(str(position), size = 15)\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["- For Data Science Manager, Data Scientist and Machine Learning Engineer, California is the state that hire the most position\n","- For Data Analyst, it seems that New York hires the most position, follow closely by California"]},{"cell_type":"markdown","metadata":{},"source":["## Text Analysis <a id='textanalysis'></a>"]},{"cell_type":"markdown","metadata":{},"source":["In this section, I will focus on the Job Description column of the data. By using libraries like **re, wordcloud, matplotlib**, I hope to gain further insights on the requirements for the field of data science. I will try to answer the following questions:\n","- What are the companies looking for when hiring?\n","- How many years of experience do they required?\n","- What level of education do the companies prefer?"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Example of a description value\n","df.description.values[0][0:int(len(df.description.values[0])/2)]"]},{"cell_type":"markdown","metadata":{},"source":["### Text Cleaning and Prepration <a id='textclean'></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Combine the desciptions by the job tilte\n","data = data.groupby('position').agg(lambda col: ' '.join(col))\n","data = data[['description']]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Create a function to clean text data\n","def clean_text(text):\n","    text = re.sub('[%s]' % re.escape(string.punctuation), '', text).lower() #remove punctutations\n","    text = re.sub('\\w*\\d\\w*', '', text)\n","    text = re.sub('[‘’“”…]', '', text)\n","    text = re.sub('\\n',' ',text)\n","    return text"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Clean the text data and remove the job title 'Others'\n","clean = lambda x :clean_text(x)\n","df_clean = pd.DataFrame(data.description.apply(clean))\n","df_clean = df_clean[df_clean.index != 'Others'].copy()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Lemmentize the text data to improve analysis\n","lemmer = WordNetLemmatizer()\n","df_clean['description'] = df_clean.description.apply(lambda x: word_tokenize(x))\n","df_clean['description'] = df_clean.description.apply(lambda x : [lemmer.lemmatize(y) for y in x])\n","df_clean['description'] = df_clean.description.apply(lambda x: ' '.join(x))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Add words that frequently appear in the descriptions but carry no value to the list of stop words\n","from sklearn.feature_extraction import text\n","extra_stopword = ['data','experience','work','team','will','skill','year','skills']\n","stop_words = text.ENGLISH_STOP_WORDS.union(extra_stopword)"]},{"cell_type":"markdown","metadata":{},"source":["### Word Cloud <a id='wordcloud'></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from wordcloud import WordCloud\n","\n","wc = WordCloud(stopwords=stop_words, background_color=\"white\", colormap=\"Dark2\",\n","             random_state=42, collocations = False, width=1600, height=800)\n","i = 0\n","fig = plt.figure(figsize=(15,8))\n","for x in df_clean.description.index:\n","    wc.generate(df_clean.description[str(x)])\n","    \n","    i += 1\n","    fig.add_subplot(2, 2, i)\n","    plt.imshow(wc, interpolation=\"bilinear\")\n","    plt.axis(\"off\")\n","    plt.title(str(x), size = 15)\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["Here are my interpretations from looking at the WordCloud:\n","- Data Analyst will be doing **research**, **analysis** and **provide** insights to facilitate better **business** decision.\n","- Data Science Manager will be in charge of **developing** **product** to help **business** serve its **customer** better.\n","- Data Scientist will be doing **research**, implementing **machine learning** and building **model** to come up with business solution.\n","- Machine Learning Engineer will **design** and **develop** **software** for business or customer. "]},{"cell_type":"markdown","metadata":{},"source":["### Year of Experience Required <a id='experience'></a>"]},{"cell_type":"markdown","metadata":{},"source":["In the following section, I will utilize regular expression to search and locate text strings with in a document.\n","\n","*Note: I'm still a novice with regex so any recommendation on how to improve my matches will be very much appreciated!*"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["text = df.description.values"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Print out the first 5 examples of matches\n","limit = 0\n","for t in text:\n","    for sentance in t.split('\\n'):\n","        if 'experience' in sentance:\n","            year = re.findall(\"\\d{1,2}\\+? year\", sentance)\n","            if len(year)==1:\n","                print(year[0])\n","                print(sentance)\n","                print(\"*\"*20)\n","                limit +=1\n","    if limit >= 5:\n","        break"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Compile the year value found into a list\n","experience_req = []\n","for t in text:\n","    for sentance in t.split('\\n'):\n","        if 'experience' in sentance:\n","            year = re.findall(\"\\d{1,2}\\+? year\", sentance)\n","            if len(year)==1:\n","                num = year[0].split(' ')\n","                experience_req.append(num[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Remove the '+' sign after year value\n","for n,i in enumerate(experience_req):\n","    if \"+\" in i:\n","        experience_req[n] = re.sub(r'\\+','',i)\n","experience_req = [int(item) for item in experience_req]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Remove outliers\n","for n,i in enumerate(experience_req):\n","    if i >= 20:\n","        experience_req.pop(n)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plt.figure(figsize = (10,5))\n","plt.hist(experience_req,bins = list(range(0,21,2)), align = 'left')\n","plt.title('Experience Required Distribution', size = 15)\n","plt.ylabel('Bin Count')\n","plt.xlabel('Year of Expereience', size = 12)\n","plt.show()\n","print(f'The average year of experience required is {round(np.mean(experience_req),2)} years')"]},{"cell_type":"markdown","metadata":{},"source":["### Skill Requirement <a id='skill'></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Create a regex search function\n","def count_text(patt,text):\n","    pattern = re.compile(patt)\n","    count = 0\n","    for t in text:\n","        if pattern.search(t):\n","            count+=1\n","    return count"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Create a data frame with skills name and regex pattern to search with\n","skills = ['R','Python','Hadoop','SQL','Tableau','TensorFlow','Agile','Power BI','SSaS','Algorithm','Java','Visualization']\n","\n","skill_patt = ['\\WR\\W+\\s*','(?i)\\WPython\\W','(?i)\\WHadoop\\W?','(?i)SQL\\w*','(?i)\\WTableau\\W?',\n","              \"(?i)\\WTensorFlow\\W?\",\"(?i)\\WAgile\\W?\",\"(?i)\\WPower\\s?BI\\W?\",\n","             \"(?i)\\WSSAS\\W?\",\"(?i)\\WAlgorithms?\\W?\",'(?i)Java\\w*','(?i)\\WVisualization\\W?']\n","\n","skill_df =pd.DataFrame(\n","    {\"skill\": skills,\n","     \"regex_pattern\":skill_patt})"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Iterate through the list of skill using the search function created\n","i = []\n","for x in skill_df['regex_pattern']:\n","    i.append(count_text(x,text))\n","skill_df['count'] = i\n","skill_df['ptg'] = round(skill_df['count']/len(text),2)\n","skill_df"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["x = skill_df.sort_values(by = 'ptg')\n","ax =x['ptg'].plot(kind = \"barh\",figsize = (10,5))\n","ax.set_title('Skills as Percentage of Total Job Description', size = 15)\n","ax.set_yticklabels(x['skill'], size = 12)\n","ax.set_xticklabels(['{:.0%}'.format(x) for x in ax.get_xticks()])\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["### Degree Requirement <a id='degree'></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Define regex pattern and seach for PhD\n","pattern = re.compile('(?i)\\WPh.?D\\W')\n","pattern2 = re.compile('(?i)\\WDoctorate\\W')\n","count = 0\n","for t in text:\n","    if pattern.search(t):\n","        count +=1\n","    elif pattern2.search(t):\n","        count +=1\n","degree = {\"PhD\": count}"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Define regex pattern and seach for Master \n","pattern = re.compile(\"(?i)\\WMasters?'?s?\\W\")\n","pattern2 = re.compile('(?i)\\WM.?S\\W')\n","count = 0\n","for t in text:\n","    if pattern.search(t):\n","        count +=1\n","    elif pattern2.search(t):\n","        count +=1\n","degree.update({\"Master\":count})"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["degree = pd.DataFrame.from_dict(degree,orient='index',\n","                       columns=[ 'count'])\n","degree['ptg'] = degree['count']/len(text)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["ax =degree['ptg'].plot(kind = \"bar\", figsize =(10,5))\n","ax.set_title('Percentage of Total Documents')\n","ax.set_xticklabels(degree.index)\n","ax.set_yticklabels(['{:.0%}'.format(x) for x in ax.get_yticks()])\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":48648,"sourceId":88304,"sourceType":"datasetVersion"}],"dockerImageVersionId":29926,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
